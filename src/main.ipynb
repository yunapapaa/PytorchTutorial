{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# GitHub リポジトリを clone（public の場合）\n",
    "!git clone https://github.com/yunapapaa/PytorchTutorial.git\n",
    "\n",
    "# モジュールを使えるように sys.path に追加\n",
    "sys.path.append(\"/content/PytorchTutorial/src\") \n",
    "\n",
    "from dataloader import get_dataloader\n",
    "from train_val import train, val, test\n",
    "from model.my_cnn import MyCNN\n",
    "from model.cifar_resnet import ResNetBasicBlock\n",
    "from utils.common import setup_device, fixed_r_seed, get_time, show_img\n",
    "from utils.plot import plot_loss\n",
    "\n",
    "\n",
    "def main():\n",
    "    print('start main')\n",
    "\n",
    "    seed=1\n",
    "    n_epoch = 100\n",
    "    lr = 0.1\n",
    "    dataset_path = '/homes/ypark/code/working_dataset/cifar10'\n",
    "    save_dir = '/homes/ypark/code/torch_tuto/fig'\n",
    "    \n",
    "    # gpu使える場合はcudaを登録\n",
    "    device = setup_device()\n",
    "    fixed_r_seed(seed)\n",
    "\n",
    "    # データセットの読み込み\n",
    "    train_loader, val_loader, test_loader = get_dataloader(dataset_path=dataset_path, img_size=32, batch_size=128)\n",
    "    # データ拡張の適用結果を確認\n",
    "    show_img(save_path=os.path.join(save_dir, 'ex_img.png'), dataloader=train_loader)\n",
    "    \n",
    "    # モデルの定義\n",
    "    # model = MyCNN(n_class=10)\n",
    "    model = ResNetBasicBlock(depth=20, n_class=10)\n",
    "    model.to(device)\n",
    "\n",
    "    # 最適化アルゴリズムの定義\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=lr, weight_decay=1e-5, momentum=0.9)\n",
    "\n",
    "    # 学習率のスケジューラーを設定 (Cosineで 1/100 まで減衰)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    #         optimizer,\n",
    "    #         T_max=n_epoch,\n",
    "    #         eta_min=lr*0.01,\n",
    "    # )\n",
    "\n",
    "    # 損失関数の定義\n",
    "    criterion = loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    start = time.time()\n",
    "    all_training_result = []\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        interval = time.time() - start\n",
    "        interval = get_time(interval)\n",
    "        print(f\"Lr: {optimizer.param_groups[0]['lr']} , Time: {interval['time']}\")\n",
    "    \n",
    "        train_loss, train_acc = train(model, device, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = val(model, device, val_loader, criterion)\n",
    "\n",
    "        all_training_result.append([train_loss, train_acc, val_loss, val_acc])\n",
    "       \n",
    "        print(\n",
    "            f\"Epoch: [{epoch}/{n_epoch}] \\t\"\n",
    "            + f\"Train Loss: {train_loss:.6f} \\t\"\n",
    "            + f\"Train Acc: {train_acc*100:.2f}% \\t\"\n",
    "            + f\"Val Loss: {val_loss:.6f} \\t\"\n",
    "            + f\"Val Acc: {val_acc*100:.2f}% \\t\"\n",
    "        )\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # 学習率の更新\n",
    "        # scheduler.step()\n",
    "    \n",
    "    all_training_result = pd.DataFrame(\n",
    "        np.array(all_training_result),\n",
    "        columns=[\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"],\n",
    "    )\n",
    "    interval = time.time() - start\n",
    "    interval = get_time (interval)\n",
    "\n",
    "    test_loss, test_acc = test(model, device, test_loader, criterion)\n",
    "    print(\n",
    "        f\"Time: {interval['time']}  Test loss: {test_loss:.6f}  Test Acc: {test_acc*100:.2f}\")\n",
    "\n",
    "    all_training_result.loc[\"test_acc\"] = test_acc\n",
    "    all_training_result.loc[\"test_loss\"] = test_loss\n",
    "    # all_training_result.to_csv(save_file_path, index=False)\n",
    "\n",
    "    plot_loss(os.path.join(save_dir, \"graph.png\"), all_training_result)\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
