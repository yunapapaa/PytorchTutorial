{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PytorchTutorial in Colab\n",
                "\n",
                "このノートブックは、以下の各ファイルの内容を統合して Colab 上で実行できるようにまとめたものです。\n",
                "\n",
                "- `common.py`\n",
                "- `augment.py`\n",
                "- `plot.py`\n",
                "- `dataloader.py`\n",
                "- `train_val.py`\n",
                "- `my_cnn.py`\n",
                "- `cifar_resnet.py`\n",
                "- `main.py`\n",
                "\n",
                "※ エポック数などは Colab で手早く動作させるために短縮しています。"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 必要なライブラリのインストール\n",
                "!pip install torch torchvision matplotlib\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### 諸々の定義\n",
                "\n",
                "import random\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import torch\n",
                "\n",
                "\n",
                "def setup_device():\n",
                "    if torch.cuda.is_available():\n",
                "        device = torch.device(\"cuda\")\n",
                "        torch.backends.cudnn.benchmark = True\n",
                "\n",
                "    else:\n",
                "        device = \"cpu\"\n",
                "\n",
                "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
                "    return device\n",
                "\n",
                "\n",
                "def fixed_r_seed(seed):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "\n",
                "\n",
                "def get_time(interval):\n",
                "    time = {\"time\" : \"{}h {}m {}s\".format(\n",
                "            int(interval / 3600), \n",
                "            int((interval % 3600) / 60), \n",
                "            int((interval % 3600) % 60))}\n",
                "    return time\n",
                "\n",
                "\n",
                "# show sample 12 imgs\n",
                "def show_img(dataloader):\n",
                "    for batched in dataloader:\n",
                "        images = batched[\"image\"]\n",
                "        labels = batched[\"label\"]\n",
                "        break\n",
                "\n",
                "    # 0-1の正規化を解除\n",
                "    images = (images - images.min()) / (images.max() - images.min())\n",
                "    \n",
                "    fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
                "    for i in range(12):\n",
                "        ax = axes[i // 4, i % 4]\n",
                "        img = np.transpose(images[i].numpy(), (1, 2, 0))  # (C, H, W) → (H, W, C)\n",
                "        ax.imshow(img)\n",
                "        ax.set_title(f\"Label: {labels[i]}\")\n",
                "        ax.axis('off')\n",
                "\n",
                "    plt.show()\n",
                "    \n",
                "\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "import os\n",
                "from PIL import Image\n",
                "\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import transforms\n",
                "\n",
                "\n",
                "class DatasetLoader(Dataset):\n",
                "    def __init__(self, root, phase, transform=None):\n",
                "        super().__init__()\n",
                "        self.transform = transform\n",
                "\n",
                "        self.image_paths = []\n",
                "        self.image_labels = []\n",
                "        self.class_name = os.listdir(os.path.join(root, phase))\n",
                "        self.class_name.sort()\n",
                "        for i, x in enumerate(self.class_name):\n",
                "            temp = sorted(glob.glob(os.path.join(root, phase, x, \"*\")))\n",
                "            self.image_labels.extend([i] * len(temp))\n",
                "            self.image_paths.extend(temp)\n",
                "\n",
                "    def __getitem__(self, index):\n",
                "        image_path = self.image_paths[index]\n",
                "        image = Image.open(image_path).convert(\"RGB\")\n",
                "\n",
                "        if self.transform is not None:\n",
                "            image = self.transform(image)\n",
                "            \n",
                "        return {\"image\": image, \"label\": self.image_labels[index]}\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "    \n",
                "\n",
                "def get_dataloader(dataset_path, img_size=32, batch_size=128):\n",
                "\n",
                "    ## データ拡張の設定 (自由に変更)\n",
                "    augmentation_list = ['rcrop', 'hflip', 'ra']\n",
                "    print(f'Apply augmentation ... {augmentation_list}')\n",
                "\n",
                "    additional_transform_list = []\n",
                "    for augment in augmentation_list:\n",
                "        # 画像の一部をランダムに切り出し\n",
                "        if augment == 'rcrop':\n",
                "            additional_transform_list.append(\n",
                "                transforms.RandomResizedCrop(size=img_size, scale=(0.5, 1.00), ratio=(1.0, 1.0))\n",
                "            )\n",
                "        # 水平反転\n",
                "        elif augment == 'hflip':\n",
                "            additional_transform_list.append(\n",
                "                transforms.RandomHorizontalFlip(p=0.5)\n",
                "            )\n",
                "        # RandAugment\n",
                "        elif augment == 'ra':  # RandAugment\n",
                "            additional_transform_list.append(\n",
                "                transforms.RandAugment(num_ops=2, magnitude=9)\n",
                "            )\n",
                "        # Color変換\n",
                "        elif augment == 'cjitter':\n",
                "            additional_transform_list.append(\n",
                "                transforms.ColorJitter(brightness=0.3,contrast=0.3,saturation=0.3,hue=0.3)\n",
                "            )\n",
                "        # グレー化\n",
                "        elif augment == 'gray':\n",
                "            additional_transform_list.append(\n",
                "                transforms.RandomGrayscale(p=0.1)\n",
                "            )\n",
                "        # 上下反転\n",
                "        elif augment == 'vflip':\n",
                "            additional_transform_list.append(\n",
                "                transforms.RandomVerticalFlip(p=1.0)\n",
                "            )\n",
                "\n",
                "    # trainにはデータ拡張を適用\n",
                "    train_transform = transforms.Compose(\n",
                "        [transforms.Resize((img_size, img_size))]\n",
                "        + additional_transform_list\n",
                "        + [transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
                "    )\n",
                "    # val, testにはデータ拡張はなし\n",
                "    test_transform = transforms.Compose(\n",
                "        [transforms.Resize((img_size, img_size))]\n",
                "        + [transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]\n",
                "    )\n",
                "\n",
                "    # データセットを読み込む\n",
                "    train_dataset = DatasetLoader(dataset_path, 'train', train_transform)\n",
                "    val_dataset = DatasetLoader(dataset_path, 'val', test_transform)\n",
                "    test_dataset = DatasetLoader(dataset_path, 'test', test_transform)\n",
                "    \n",
                "    # バッチごとに取り出せるようにDataLoaderに登録\n",
                "    train_loader = DataLoader(\n",
                "        train_dataset,\n",
                "        batch_size=batch_size,\n",
                "        shuffle=True,\n",
                "        num_workers=8,\n",
                "        pin_memory=False,\n",
                "        drop_last=False,\n",
                "    )\n",
                "    val_loader = DataLoader(\n",
                "        val_dataset,\n",
                "        batch_size=batch_size,\n",
                "        shuffle=False,\n",
                "        num_workers=8,\n",
                "        pin_memory=False,\n",
                "        drop_last=False,\n",
                "    )\n",
                "    test_loader = DataLoader(\n",
                "        test_dataset,\n",
                "        batch_size=batch_size,\n",
                "        shuffle=False,\n",
                "        num_workers=8,\n",
                "        pin_memory=False,\n",
                "        drop_last=False,\n",
                "    )\n",
                "\n",
                "    print(f'Load dataset, Num of dataset ... Train : {len(train_dataset)}  Val : {len(val_dataset)}  Test : {len(test_dataset)}')\n",
                "\n",
                "    show_img(train_loader)\n",
                "\n",
                "    return train_loader, val_loader, test_loader\n",
                "\n",
                " "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### train_val.py の内容\n",
                "def train(model, device, dataloader, optimizer, criterion):\n",
                "    model.train()\n",
                "    total_loss, correct = 0, 0\n",
                "    for data, target in dataloader:\n",
                "        data, target = data.to(device), target.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        output = model(data)\n",
                "        loss = criterion(output, target)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "        correct += (output.argmax(1) == target).sum().item()\n",
                "    avg_loss = total_loss / len(dataloader)\n",
                "    accuracy = correct / len(dataloader.dataset)\n",
                "    return avg_loss, accuracy\n",
                "\n",
                "def val(model, device, dataloader, criterion):\n",
                "    model.eval()\n",
                "    total_loss, correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        for data, target in dataloader:\n",
                "            data, target = data.to(device), target.to(device)\n",
                "            output = model(data)\n",
                "            loss = criterion(output, target)\n",
                "            total_loss += loss.item()\n",
                "            correct += (output.argmax(1) == target).sum().item()\n",
                "    avg_loss = total_loss / len(dataloader)\n",
                "    accuracy = correct / len(dataloader.dataset)\n",
                "    return avg_loss, accuracy\n",
                "\n",
                "def test(model, device, dataloader, criterion):\n",
                "    return val(model, device, dataloader, criterion)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### my_cnn.py の内容\n",
                "class MyCNN(nn.Module):\n",
                "    def __init__(self, n_class=10):\n",
                "        super(MyCNN, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
                "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
                "        self.fc2 = nn.Linear(128, n_class)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool(F.relu(self.conv1(x)))\n",
                "        x = self.pool(F.relu(self.conv2(x)))\n",
                "        x = x.view(-1, 64 * 8 * 8)\n",
                "        x = F.relu(self.fc1(x))\n",
                "        x = self.fc2(x)\n",
                "        return x\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### cifar_resnet.py の内容（簡易版）\n",
                "class ResNetBasicBlock(nn.Module):\n",
                "    def __init__(self, depth=20, n_class=10):\n",
                "        super(ResNetBasicBlock, self).__init__()\n",
                "        # ここでは簡単な例として、1層の畳み込みとプーリング・全結合層を定義\n",
                "        self.conv = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "        self.fc = nn.Linear(64 * 16 * 16, n_class)  \n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool(F.relu(self.conv(x)))\n",
                "        x = x.view(x.size(0), -1)\n",
                "        x = self.fc(x)\n",
                "        return x\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "### main.py の内容\n",
                "def main():\n",
                "    print('start main')\n",
                "\n",
                "    seed = 1\n",
                "    n_epoch = 5  # Colab 向けに短縮\n",
                "    lr = 0.01\n",
                "    dataset_path = './cifar10'\n",
                "    save_dir = './fig'\n",
                "    os.makedirs(save_dir, exist_ok=True)\n",
                "\n",
                "    # デバイス設定\n",
                "    device = setup_device()\n",
                "    fixed_r_seed(seed)\n",
                "\n",
                "    # データローダー作成\n",
                "    train_loader, val_loader, test_loader = get_dataloader(dataset_path=dataset_path, img_size=32, batch_size=128)\n",
                "\n",
                "    # データ拡張結果を確認（最初のバッチ画像を保存）\n",
                "    show_img(save_path=os.path.join(save_dir, 'ex_img.png'), dataloader=train_loader)\n",
                "\n",
                "    # モデルの定義\n",
                "    # model = MyCNN(n_class=10)\n",
                "    model = ResNetBasicBlock(depth=20, n_class=10)  # こちらを使用\n",
                "    model.to(device)\n",
                "\n",
                "    # 最適化アルゴリズムの定義\n",
                "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=1e-5, momentum=0.9)\n",
                "\n",
                "    # 損失関数の定義\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "    start_time = time.time()\n",
                "    all_training_result = []\n",
                "    for epoch in range(1, n_epoch + 1):\n",
                "        elapsed = time.time() - start_time\n",
                "        interval = get_time(elapsed)\n",
                "        print(f\"Lr: {optimizer.param_groups[0]['lr']} , Time: {interval['time']}\")\n",
                "        \n",
                "        train_loss, train_acc = train(model, device, train_loader, optimizer, criterion)\n",
                "        val_loss, val_acc = val(model, device, val_loader, criterion)\n",
                "        all_training_result.append([train_loss, train_acc, val_loss, val_acc])\n",
                "        print(\n",
                "            f\"Epoch: [{epoch}/{n_epoch}] \\t\"\n",
                "            + f\"Train Loss: {train_loss:.6f} \\t\"\n",
                "            + f\"Train Acc: {train_acc*100:.2f}% \\t\"\n",
                "            + f\"Val Loss: {val_loss:.6f} \\t\"\n",
                "            + f\"Val Acc: {val_acc*100:.2f}% \\t\"\n",
                "        )\n",
                "        sys.stdout.flush()\n",
                "\n",
                "    test_loss, test_acc = test(model, device, test_loader, criterion)\n",
                "    print(f\"Test Loss: {test_loss:.6f}  Test Acc: {test_acc*100:.2f}%\")\n",
                "\n",
                "if __name__ == '__main__':\n",
                "    main()\n"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "name": "PytorchTutorial_Colab.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
